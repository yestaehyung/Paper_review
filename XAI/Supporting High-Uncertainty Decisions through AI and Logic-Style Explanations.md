Introduction

이전의 연구는 설명이 사용자에게 ai의 조언이 틀릴지라도 더 들을 수 있도록 만든다는 것을 밝혀냄     

improving task performance를 하는 factors를 확인하는 것 
- AI 예측을 보여주는 것은 task performance를 중기 시킨다

AI prediction의 정확도를 보여주는 것은 user의 decision에 영향을 주는 것을 확인함    
Ai-related information(confidence and correctness)는 사용자의 decision making process에 큰 역할을 한다 그런데 실험 setting에 따라 다르게 영향을 미친다.     

human centered 측면에서 (적절한 설명 기술을 presenting 하고, selecting하는 것과 같은) 과 같은 연구도 있었음     
이런 연구들은 주로 알고리즘이나 설명의 presence and absence에 대한 것만 있었음    

그러나 만약에 다른 시각화를 통해 presented한다면 같은 기술이라도 다른 영향을 줄 수 있음       

최근의 연구들은 이러한 측면에 대해서 다루기 시작함, (ex contextualizing explanations or comparing visual, textual or hybrid explanations).   

이 논문에서는 설명에 의해 trigger 되는 reasoning에 초점을 맞춘다, 근데 presented data에 따라 주의 깊게 선택이 되지 않은 AI 제안에 대한 효율적이거나 비효율적인 이해  결과, ??





