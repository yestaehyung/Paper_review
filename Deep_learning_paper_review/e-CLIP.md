e-clip은 네이버 쇼핑의 멀티모달 사전학습 모델로 CIKM22 applied section에 accept 되었다고 한다. 

- 상품의 카테고리 분류
- 상품 속성 추출
- 상품 옵션 인식
- 동일 상품 매칭과 동일 상품 군집 자동화
- 성인 상품 등 부적절한 컨텐츠 제거
- 유사상품, 관심상품 추천

여러 task 를 해결하기 위해 model을 많이 사용하는데, 이 때마다 일일이 다른 모델을 개발하여 사용하기에는 어려운 문제가 있다.  
그래서 잘 pre-trained 된 model을 가지고 transfer learning 하여 여러 task 에 적용한다. 

네이버 쇼핑의 목표는 구매자가 원하는 상품/원하지 않는 상품을 빠르게 필터링 할 수 있는 기능을 만드는 것을 목표로 함.  
아래 그림은 네이버 쇼핑의 pull 구조도 임.

아래 빨간 색 부분을 간소화 하면 굉장히 효율적인 처리를 할 수 있음.  
굉장히 많은 unlabled data를 어떻게 활용하면 좋을지에 대한 탐구, self-supervised learning을 사용하자!  
CLIP 기반의 model을 개발함,  

![](https://i.imgur.com/LXsCvLW.png)

---
## 배경
수백만명의 사용자가 사용하는 검색시스템에서 다양한 task를 지원하는 것은 사용자 경험을 향상시키는데 큰 도움을 함  
이럴 때 일반적으로는 여러 머신러닝 모델을 사용하여, 또는 단일 프레임워크를 사용하여 개발하였기 때문에 관리나 새로운 task에 대한 대처 같은 것들이 어려웠다.  

그런데 이제 CLIP이나 ALIGN과 같은 대규모 vision + text 모델의 VLP 방법론이 등장하면서 위에서 제기한 문제를 해결할수 있지 않을까라는 생각을 들게 하였다.  
여기서 말하는 두 모델의 장점은 아래와 같다
1. 다운 스트림 작업에서 높은 정확도를 보여준다. 경우에 따라서 fine-tuning 하지 않아도 높은 정확도를 보인다.
2. 이런 모델은 두개의 독립된 모델이 존재한다(image, text) 따라서 독립적으로 task에 활용할 수 있다는 것이 장점이다.
3. 레이블이 없는 데이터에서도 잘 작동한다. 

## 문제
이렇게 좋은 모델이 나왔는데, 이 것을 아직 전자 상거래에서 사용할 수 있을 만큼의 방법이 충분하게 논의되지 않았다.  
막상 전자 상거래에 적용을 하려고 해도 어려움이 많다.  
1. 데이터에 노이즈가 많다 -> 네이버 이커머스의 특징상, 수많은 사람들이 제품을 등록하고, 이에 따라 데이터 노이즈가 발생하게 된다. 또한 제품의 제목에 관련 없는 정보는 모델의 학습을 방해한다.
2. 중복, 유사 제품 -> 판매자가 동일한  상품을 여러번 등록하게 될 경우, 훈련 중에 이러한 상품을 모델이 다르게 학습하게 된다. 이는 contrastive loss 에 방해하게 된다.
3. Irregularity and Sparsity -> 전자 상거래의 제품 텍스트는 제품에 대한 요약된 세부 사항으로 구성되며 문법에 대한 구조가 부족하다?(제대로 된 설명이 부족한 상품이 많다.)
4. 제한된 컴퓨팅 자원 -> 이러한 모델은 많은 컴퓨팅 자원을 필요로 하기 때문에 이를 고려해야한다. 
5. Model convergence -> 대규모 배치를 가지는 경우 수렴 속도가 늦다. 

## 이 논문에서 하려고 하는 것
위에서 말한 문제를 해결하기 위해 e-CLIP을 제안한다. NAVER SHOPPING의 전반적인 구조에 대해 설명하고, 학습한  e-CLIP을 어떤 downstream task에 활용할 수 있을지 확인한다. 