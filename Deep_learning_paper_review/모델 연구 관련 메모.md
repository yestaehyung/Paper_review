FashionVil -> 다른 패션 데이터를 많이 사용했다.  
TCL -> FashionGen 만으로 학습을 했을 때 FashionVil과 성능이 비슷하였다.  

Sim을 구할 때 왜 Original * Momentum 일까? 

TCL VS ALBEF code 적으로 어떤 부분이 다른지 확인해서 알렫드리기
Fashion retreival에서 diversity를 볼 수 있는 논문 탐색
TCL code 탐색하기

----- 
## ALBEF 


```
# batch 내 이미지들의 [CLS] 토큰 embedding
image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]), dim = -1)
```



![](https://i.imgur.com/KHsCedi.png)

## TCL

forward를 할 때 image_aug 를 매개 변수로 받음, 그러나 text_aug는 매개변수로 받지는 않음
또한 모멘텀에 들어가는 text와 encoder에 들어가는 text가 동일함(augment를 과연하였는가?)

```
# batch 내 이미지들의 [CLS] 토큰 embedding
image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]), dim = -1)

# batch 내 이미지들의 [CLS] 토큰 embedding
image_feat_m_l = F.normalize(self.vision_proj_m(image_embeds_m[:,1:,:]), dim = -1)

```


![](https://i.imgur.com/6F3FiZj.png)






----
## Hard Negative Mixing for contrastive learning

Hard negative example 이 중요한 feature이고 이게 learn discriminative features한다.

Hard negative sampling -> 어떻게 batch에서 hard negative를 뽑아내느냐   

Negative 끼리 mixing?
