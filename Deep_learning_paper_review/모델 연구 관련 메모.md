FashionVil -> 다른 패션 데이터를 많이 사용했다.  
TCL -> FashionGen 만으로 학습을 했을 때 FashionVil과 성능이 비슷하였다.  

Sim을 구할 때 왜 Original * Momentum 일까? 

TCL VS ALBEF code 적으로 어떤 부분이 다른지 확인해서 알렫드리기
Fashion retreival에서 diversity를 볼 수 있는 논문 탐색
TCL code 탐색하기

----- 
## ALBEF 


```
# image 를 visual encoder에 입력으로 준 뒤 [CLS] 토큰만 linear layer을 거치고,
# normalize 해서 ITC 위한 image feature 을 추출
# image_embeds[:, 0, :] batch 내 이미지들의 [CLS] 토큰 embedding
image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]), dim = -1)

# torch.no_grad()는 역전파가 적용되지 않음, 모멘텀 모델을 위한 것임
```

1. queue를 이용해 현재 및 이전 batch 내에 있던 momentum image, text feature를 저장
2. 현재 batch 내의 feature과 queue에 있는 feature를 이용해 sim matrix 생성
3. momentum model로 얻은 sim_i2t_m, sim_t2i_m이 pseudo-target 이 됨 (i2t: image to text)
   - 각 행을 sum 하면 1이 되게끔 해줌
4. sim matrix 과 같은 size의 행렬 생성한 뒤, positive pair에 해당하는 diagonal term은 1로, 나머지 off-diagonal term은 negative pair이므로 0으로 만들어 ground truth label 생성
5. pseudo-target과 ground truth label을 convex combination 해서 최종 target으로 생성

결과적으로 positive pair는 embedding space에서 가까워지게, negative pair는 멀어지게 학습하면서 momentum distillation으로 iamge-text 사이의 유사도 반영하여 학습


![](https://i.imgur.com/KHsCedi.png)

## TCL

forward를 할 때 image_aug 를 매개 변수로 받음, 그러나 text_aug는 매개변수로 받지는 않음
또한 모멘텀에 들어가는 text와 encoder에 들어가는 text가 동일함(augment를 과연하였는가?)

```
# batch 내 이미지들의 [CLS] 토큰 embedding
image_feat_m = F.normalize(self.vision_proj_m(image_embeds_m[:,0,:]), dim = -1)

# batch 내 이미지들의 [CLS] 제외 토큰 embedding
image_feat_m_l = F.normalize(self.vision_proj_m(image_embeds_m[:,1:,:]), dim = -1)
image_feat_m_l = self.patch_pooling(image_feat_m_l) # pooling for image patches

# batch 내 텍스트 들의 [CLS] 토큰 embedding
text_feat_m = F.normalize(self.text_proj_m(text_output_m[:,0,:]), dim = -1)

# batch 내 텍스트 들의 [CLS] 제외 토큰 embedding
text_feat_m_l = F.normalize(self.text_proj_m(text_output_m[:,1:,:]), dim = -1)
```


![](https://i.imgur.com/6F3FiZj.png)

아까 위에서 cls 제외 토큰들을 normalize 한 것을 pooling 하기 위한 코드
![](https://i.imgur.com/a2B39J3.png)

![](https://i.imgur.com/THAwSYU.png)


----
## Hard Negative Mixing for contrastive learning

Hard negative example 이 중요한 feature이고 이게 learn discriminative features한다.

Hard negative sampling -> 어떻게 batch에서 hard negative를 뽑아내느냐   

Negative 끼리 mixing?
