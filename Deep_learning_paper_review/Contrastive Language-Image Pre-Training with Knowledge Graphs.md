# Abstract

이전의 연구 접근은 간단한 image-text pair에만 집중하고, 다른 modal의 semantic connection을 무시했다.    
Knowledge base pretrain framework를 제안-Knowledge CLIP.    
CLIP에 semantic한 정보를 주입한 방법, 이러한 방법을 통해서 높은 퀄리티의 vision 과 language modal의 represnetaion을 align시킴    

# Introduction

VLP -> multi-modal data에 대해서 representation을 학습하고, downstream task에 쉽게 접근할 수 있도록 함    

